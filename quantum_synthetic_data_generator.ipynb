{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmQhZ2feVsSJ0xCEquNECK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacquieAM/ai-projects/blob/main/quantum_synthetic_data_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1X5UIdukPgd"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 openai\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gradio as gr\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "# import torch, json\n"
      ],
      "metadata": {
        "id": "2eCW8iTgn8ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW8nl3XRFrz0"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import gradio as gr\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "import torch\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "id": "meyO8ivoefSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "gyscYtBNoKXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sign in to HuggingFace Hub\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "_uB1D83Uokwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ],
      "metadata": {
        "id": "bxMy0O87pVUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " system_message = (\n",
        "      \"You are a specialized synthetic data generator that produces\"\n",
        "      \"structured, JSON-formatted datasets for quantum computing research and simulations.\"\n",
        "  )"
      ],
      "metadata": {
        "id": "SENlv3aOwcli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = (\n",
        "    \"Generate 5 synthetic quantum circuit configurations. \"\n",
        "    \"Each record must include: circuit_id, number_of_qubits (1-20), \"\n",
        "    \"gate_types (choose from H, X, Y, Z, CNOT, T, S), depth (1-50), \"\n",
        "    \"fidelity (0-1), error_rate (0-0.1). Output as a JSON array.\"\n",
        ")"
      ],
      "metadata": {
        "id": "7tLrfN54-4XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_records = 5"
      ],
      "metadata": {
        "id": "xhCZxCBAgX8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_templates = {\n",
        "    \"Quantum Circuits\":(\n",
        "        f\"Generate {num_records} synthetic quantum circuit configurations.\"\n",
        "        \"Each record must include: circuit_id, number_of_qubits (1-20),\"\n",
        "        \"gate_types (choose from H, X, Z, CNOT, T, S), depth (1-50),\"\n",
        "        \"fidelity (0-1), error_rate (0-0.1). Output as a JSON array.\"\n",
        "    ),\n",
        "    \"Quantum Experiment Logs\":(\n",
        "        f\"Generate {num_records} synthetic quantum experiment logs.\"\n",
        "        \"Each record must include: experiment_id, timestamp, qubit_state ( |0>, |>, superposition), \"\n",
        "        \"measurement_result (matches qubit_state), decoherence_time (0.1-100 microseconds). Output as JSON.\"\n",
        "    ),\n",
        "    \"Quantum Research Abstracts\": (\n",
        "        f\"Generate {num_records} synthetic quantum research abstracts.\"\n",
        "        \"Each record must include: title, abstract_text, keywords, year (2000-2025).\"\n",
        "        \"Focus on coherence and topic relevance. Output as JSON.\"\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "YW0NIKlQweJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"<|system|>\\n{system_message}\\n<|user|>\\n{user_message}\\n<|assistant|>\\n\""
      ],
      "metadata": {
        "id": "PKe1q9xw-7Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLAMA,\n",
        "    device_map=\"auto\",\n",
        "    # device_map=None,\n",
        "    quantization_config=quant_config\n",
        ")\n",
        "outputs = model.generate(**inputs, max_new_tokens=200)\n",
        "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "s-8fuiUapbur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def generate_data(dataset_type, num_records, file_format):\n",
        "    # Prepare prompt for the model\n",
        "    user_message = prompt_templates[dataset_type].format(num_records=num_records)\n",
        "    prompt = f\"<|system|>\\n{system_message}\\n<|user|>\\n{user_message}\\n<|assistant|>\\n\"\n",
        "\n",
        "    # Tokenize and generate model output\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=800)\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Parse only the first JSON array\n",
        "    try:\n",
        "        # Find first opening bracket\n",
        "        start = text.find(\"[\")\n",
        "        if start == -1:\n",
        "            raise ValueError(\"No JSON array found in model output\")\n",
        "\n",
        "        # Count brackets to find the matching closing bracket\n",
        "        open_brackets = 0\n",
        "        end = start\n",
        "        while end < len(text):\n",
        "            if text[end] == \"[\":\n",
        "                open_brackets += 1\n",
        "            elif text[end] == \"]\":\n",
        "                open_brackets -= 1\n",
        "                if open_brackets == 0:\n",
        "                    break\n",
        "            end += 1\n",
        "        else:\n",
        "            raise ValueError(\"No matching closing bracket found\")\n",
        "\n",
        "        data = json.loads(text[start:end+1])\n",
        "    except Exception as e:\n",
        "        error_data = [{\"error\": f\"JSON parsing error: {str(e)}\", \"raw_text\": text}]\n",
        "        return json.dumps(error_data, indent=2)\n",
        "\n",
        "    # CSV conversion (keep your existing logic)\n",
        "    if file_format.upper() == \"CSV\":\n",
        "        try:\n",
        "            csv_data = []\n",
        "            for row in data:\n",
        "                row_copy = row.copy()\n",
        "                # Fix qubit_state for readability in CSV\n",
        "                if \"qubit_state\" in row_copy:\n",
        "                    if row_copy[\"qubit_state\"] in [\"|>\", \"superposition\"]:\n",
        "                        row_copy[\"qubit_state\"] = \"|0> + |1>\"\n",
        "                csv_data.append(row_copy)\n",
        "\n",
        "            df = pd.DataFrame(csv_data)\n",
        "            return df.to_csv(index=False)\n",
        "        except Exception as e:\n",
        "            return f\"CSV conversion error: {str(e)}\\n\\nData:\\n{data}\"\n",
        "\n",
        "    # Return JSON string if not CSV\n",
        "    return json.dumps(data, indent=2)\n"
      ],
      "metadata": {
        "id": "n5g8U62w9F2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UfVwPGcA8zmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradio\n",
        "dataset_types = [\n",
        "    \"Quantum Circuits\",\n",
        "    \"Quantum Experiment Logs\",\n",
        "    \"Quantum Research Abstracts\"\n",
        "]\n",
        "\n",
        "file_formats = [\"JSON\", \"CSV\"]\n",
        "\n",
        "with gr.Blocks(title=\"Quantum Synthetic Data Generator\") as ui:\n",
        "  gr.Markdown(\n",
        "      \"\"\"\n",
        "      Quantum Synthetic Data Generator\n",
        "      Generate realistic, structured **synthetic datasets** for quantum computing research, simulations, or educational purposes.\n",
        "      Powered by open-source **Llama 3.1 8B Instruct**.\n",
        "      \"\"\"\n",
        "  )\n",
        "\n",
        "  dataset = gr.Dropdown(choices=dataset_types, label=\"Select Dataset Type\", value=\"Quantum Circuits\")\n",
        "  count = gr.Slider(1, 20, step=1, value=5, label=\"Number of Records\")\n",
        "  file_format = gr.Dropdown(choices=file_formats, label=\"File Format\", value=\"JSON\")\n",
        "\n",
        "  output = gr.Code(label=\"Generated Data\", language=\"json\")\n",
        "  generate_btn = gr.Button(\"Generate Quantum Data\")\n",
        "\n",
        "  generate_btn.click(\n",
        "      fn=generate_data,\n",
        "      inputs=[dataset, count, file_format],\n",
        "      outputs=output\n",
        "  )\n",
        "\n",
        "  ui.launch(share=True)"
      ],
      "metadata": {
        "id": "N8m6Ump42crP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}