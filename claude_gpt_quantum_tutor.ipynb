{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331773a0-36bf-45ab-85fb-0616b9f179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Computing Tutor with GPT & Claude\n",
    "An interactive dual-AI notebook where GPT teaches and Claude asks questions, creating a dynamic learning experience that makes quantum computing concepts clear, engaging, and fun for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f2a5-8814-421f-b58e-b94c22a97cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which llm will have which role  and system prompts\n",
    "professor_model = \"gpt-4.1-mini\"\n",
    "student_model = \"claude-3-5-haiku-latest\"\n",
    "\n",
    "professor_system = (\n",
    "    \"You are a fun, smart quantum computing professor. \" \\\n",
    "    \"You explain ideas clearly using simple example and mnemonics.\"\\\n",
    "    \"Keep your answers concise (~200 words) and avoid very long paragraphs.\"\\\n",
    "    \"But always finish each explanation completely - do not stop mid-sentence or mid-concept.\"\\\n",
    "    \"Do not use phrases like 'Great question' or 'Excellent understanding' at the start.\"\\\n",
    "    \"Instead, begin directly by introducing or explaining the concept.\"\n",
    ")\n",
    "\n",
    "student_system = (\n",
    "    \"You are a curious beginner in quantum computing.\" \\\n",
    "    \"You ask questions when confused and want to understand everything.\"\\\n",
    "    \"Keep your questions or follow up short.\"\\\n",
    "    \"Do not comment on the professor tone, or anything outside of what you are learning.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce539e90-165f-4d6c-b810-06d704d17436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_professor():\n",
    "    messages = [{\"role\": \"system\", \"content\": professor_system}]\n",
    "    for prof_msg, student_msg in zip(professor_messages, student_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": prof_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": student_msg})\n",
    "    response = openai.chat.completions.create(\n",
    "        model=professor_model,\n",
    "        messages=messages,\n",
    "        # max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b9390-a679-4da1-a93f-58a8ccd6b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_student():\n",
    "    messages = []\n",
    "    #messages = [{\"role\": \"system\", \"content\": student_system}]\n",
    "    for prof_msg, student_msg in zip(professor_messages, student_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": prof_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": student_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": prof_msg[-1]})    \n",
    "    response = claude.messages.create(\n",
    "        model=student_model,\n",
    "        system=student_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.content[0].text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75264538-a456-4df0-a2c0-25530851b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "# professor speaks and teaches a concept\n",
    "    prof_next = call_professor()\n",
    "    #print(f\"Professor:\\n{prof_next}\\n\")\n",
    "    professor_messages.append(prof_next)\n",
    "    # Clean and print\n",
    "    clean_prof = prof_next.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    print(f\"Professor:\\n{clean_prof}\\n\", end=\"\", flush=True)\n",
    "\n",
    "#Student responds or asks questions\n",
    "    student_next = call_student()\n",
    "    print(f\"Student:\\n{student_next}\\n\")\n",
    "    student_messages.append(student_next)\n",
    "   # clean_student = student_next.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "   # print(f\"Student:\\n{clean_student}\\n\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb873f-889f-4cb3-966b-0c383bc61889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
