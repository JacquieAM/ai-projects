{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df389cdb-51f7-42a9-87f0-0cb5afe34a16",
   "metadata": {},
   "source": [
    "# RAG Linux Command Assistant + Automated Evaluation\n",
    "\n",
    "A follow-up to Project 9 : RAG and Fine-Tuning Comparison on a Linux Commands Dataset, this RAG chatbot uses Ollama's `llama3.2` and three Linux command datasets. Using `PromptTemplate` for structured prompts, it delivers accurate, relevant, and detailed command-line answers. Includes an automated evaluation suite to test responses with flexible scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b146d-a2d4-4a28-ae88-0a760359b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b201551-d745-4538-9bb3-6d566d01dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load environment variables\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28f3fc-77dd-4dab-a6ad-e22e176c8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.llms import Ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd04fb3-1328-4401-9429-9cef72d59013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama api\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "db_name = \"RAG_vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ba8d-0154-47e8-b819-638fa24e5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8da541-28bd-40c2-abf3-6cab67d4fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config \n",
    "#datasets can have different splits(train/test/validation), column names  for instruction and answer fields\n",
    "# putting this in a dictionary list allows to loop over multiple datasets and treat them in a unified way\n",
    "DATASETS = [\n",
    "    {\n",
    "        \"name\": \"harpomaxx/unix-commands\",\n",
    "        \"split\": \"train\",\n",
    "        \"instruction_col\": \"instruction\",\n",
    "        \"output_col\": \"output\",\n",
    "        \"tag\": \"unix_commands\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"shikhardadhich/linux_commands\",\n",
    "        \"split\": \"train\",\n",
    "        \"instruction_col\": \"Instruction\",\n",
    "        \"output_col\": \"Output\",\n",
    "        \"tag\": \"linux_commands\"\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mecha-org/linux-command-dataset\",\n",
    "        \"split\": \"train\",\n",
    "        \"instruction_col\": \"input\",\n",
    "        \"output_col\": \"output\",\n",
    "        \"tag\": \"linux_cmd_mecha\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b39b4-9443-42d0-b6e4-e2f14422b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load, normalize and tag\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "#loop through each dataset config\n",
    "for ds in DATASETS:\n",
    "    dataset = load_dataset(ds[\"name\"], split=ds[\"split\"])\n",
    "    #read instruction/output\n",
    "    text_col = ds[\"instruction_col\"]\n",
    "    answer_col = ds[\"output_col\"]\n",
    "\n",
    "    #convert each row of the dataset into a langchain document\n",
    "    def add_metadata(record):\n",
    "        #extract all fields except instruction + answer\n",
    "        metadata = {k: v for k, v in record.items() if k not in [text_col, answer_col]}\n",
    "        # add custom metadata field to identify source dataset\n",
    "        metadata[\"doc_type\"] = ds[\"tag\"]\n",
    "\n",
    "        #create unified text format -merges instruction and answer together (this will be mbedded for RAG)\n",
    "        content = f\"Instruction: {record[text_col]}\\nAnswer: {record[answer_col]}\"\n",
    "        return Document(page_content=content, metadata=metadata)\n",
    "       \n",
    "    #convert every record into a document\n",
    "    docs = [add_metadata(r) for r in dataset if r.get(text_col)]\n",
    "    #add processed documents for this dataset into the global list\n",
    "    all_documents.extend(docs)\n",
    "        \n",
    "        \n",
    "print(f\"Loaded {len(all_documents)} combined documents\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f285d7a-204b-4c28-8f53-20eda4efe5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug and verify column names\n",
    "ds1 = load_dataset(\"harpomaxx/unix-commands\", split=\"train\")\n",
    "ds2 = load_dataset(\"shikhardadhich/linux_commands\", split=\"train\")\n",
    "ds3 = load_dataset(\"mecha-org/linux-command-dataset\", split=\"train\")\n",
    "\n",
    "print(ds1.column_names)\n",
    "print(ds2.column_names)\n",
    "print(ds3.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d99bb-3a76-46d0-92d7-e08eb0e8522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_deduplicate(docs):\n",
    "    seen = set()\n",
    "    clean_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        #strip whitespace\n",
    "        lines = [line.strip() for line in doc.page_content.splitlines()]\n",
    "        content = \"\\n\".join(lines)\n",
    "        #collapse multiple spaces into one space \n",
    "        content = \" \".join(content.split())\n",
    "\n",
    "        #deduplicate\n",
    "        if content not in seen:\n",
    "            seen.add(content)\n",
    "            #create a new document with the same metadata\n",
    "            clean_docs.append(Document(page_content=content, metadata=doc.metadata))\n",
    "    \n",
    "    return clean_docs        \n",
    "\n",
    "#apply normalization and deduplication\n",
    "all_documents_clean = normalize_and_deduplicate(all_documents)\n",
    "print(f\"Documents after normalization and deduplication: {len(all_documents_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7db26-d147-4385-9f72-11a9eb51f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(all_documents_clean)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25049b6-c67c-4e0a-8bd2-787c3027ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check chunk character size in 3 first chunks\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"Chunk {i+1} length: {len(chunk.page_content)} chars\")\n",
    "    print(chunk.page_content)\n",
    "    print(chunk.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a20c6-ca2e-4bca-8558-58c0ac9a41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41592aeb-81ca-44a4-9a8a-92db156747bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "\n",
    "print(f\"Vectorstore created with {count:,} documents\")\n",
    "print(f\"Each embedding has {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89998600-accd-4a40-84c2-e47a0631d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a precise, highly knowledgeable Linux command assistant.\n",
    "Always answer with:\n",
    "- The most complete and standard Linux command, not minimal versions.\n",
    "- a brief explanation.\n",
    "- an example when useful.\n",
    "- use the recursive version if applicable.\n",
    "- never shorten commands.\n",
    "\n",
    "\n",
    "Use the retrieved context below if relevant.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d24257-6985-47b5-932b-34fc1dd2d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm = Ollama(temperature=0.7, model=MODEL),\n",
    "    retriever = retriever,\n",
    "    memory = memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a45e52-6c2c-4a0f-9045-bb68a8046334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b49cc-8758-4354-b41b-2eaffe4ad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2243e79-c8b5-40d4-aa64-b37ec3366a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing RAG repsonses\n",
    "\n",
    "# --- 1. Define test cases --------------------------------------------------\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"How do I list all files in a directory including hidden ones?\",\n",
    "        \"expected_keywords\": [\"ls -a\", \"ls -la\", \"hidden\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I find a file containing a specific text string?\",\n",
    "        \"expected_keywords\": [\"grep\", \"grep -r\", \"string\", \"filename\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain the difference between grep and sed.\",\n",
    "        \"expected_keywords\": [\"grep\", \"sed\", \"search\", \"edit\", \"replace\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I search for a file by name?\",\n",
    "        \"expected_keywords\": [\"find\", \"-name\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"And how about searching inside files?\",\n",
    "        \"expected_keywords\": [\"grep\", \"string\", \"file\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- 2. Loosened evaluation function ---------------------------------------\n",
    "\n",
    "def score_answer(answer, expected_keywords, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Loosened evaluation:\n",
    "    - Partial score for each keyword found\n",
    "    - Pass if ratio >= threshold\n",
    "    \"\"\"\n",
    "    answer_lower = answer.lower()\n",
    "    score = 0\n",
    "    for kw in expected_keywords:\n",
    "        # simple substring OR regex for variations\n",
    "        pattern = re.escape(kw.lower())\n",
    "        if re.search(pattern, answer_lower):\n",
    "            score += 1\n",
    "\n",
    "    total = len(expected_keywords)\n",
    "    ratio = score / total\n",
    "    passed = ratio >= threshold  # pass if >= threshold (60% by default)\n",
    "    return score, total, passed\n",
    "\n",
    "# --- 3. Run evaluation ------------------------------------------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "for test in test_cases:\n",
    "    q = test[\"question\"]\n",
    "    expected = test[\"expected_keywords\"]\n",
    "\n",
    "    response = chat(q, history=[])  # no conversation memory\n",
    "    score, total, passed = score_answer(response, expected)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"response\": response,\n",
    "        \"score\": score,\n",
    "        \"total\": total,\n",
    "        \"passed\": passed\n",
    "    })\n",
    "\n",
    "# --- 4. Print report --------------------------------------------------------\n",
    "\n",
    "for result in results:\n",
    "    print(\"\\n--------------------------------------------------\")\n",
    "    print(\"Question:\", result[\"question\"])\n",
    "    print(\"Model Response:\", result[\"response\"])\n",
    "    print(f\"Score: {result['score']} / {result['total']}\")\n",
    "    print(\"Status:\", \" PASS\" if result[\"passed\"] else \" FAIL\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
