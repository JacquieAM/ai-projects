{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df389cdb-51f7-42a9-87f0-0cb5afe34a16",
   "metadata": {},
   "source": [
    "# RAG Linux Command Assistant + Automated Evaluation\n",
    "\n",
    "A follow-up to Project 9 : RAG and Fine-Tuning Comparison on a Linux Commands Dataset, this RAG chatbot uses Ollama's `llama3.2` and three Linux command datasets. Using `PromptTemplate` for structured prompts, it delivers accurate, relevant, and detailed command-line answers. Includes an automated evaluation suite to test responses with flexible scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b146d-a2d4-4a28-ae88-0a760359b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b201551-d745-4538-9bb3-6d566d01dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load environment variables\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28f3fc-77dd-4dab-a6ad-e22e176c8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.llms import Ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd04fb3-1328-4401-9429-9cef72d59013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama api\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "db_name = \"RAG_vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ba8d-0154-47e8-b819-638fa24e5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8da541-28bd-40c2-abf3-6cab67d4fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config \n",
    "#datasets can have different splits(train/test/validation), column names  for instruction and answer fields\n",
    "# putting this in a dictionary list allows to loop over multiple datasets and treat them in a unified way\n",
    "DATASETS = [\n",
    "    {\n",
    "        \"name\": \"harpomaxx/unix-commands\",\n",
    "        \"split\": \"train\",\n",
    "        \"instruction_col\": \"instruction\",\n",
    "        \"output_col\": \"output\",\n",
    "        \"tag\": \"unix_commands\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"shikhardadhich/linux_commands\",\n",
    "        \"split\": \"train\",\n",
    "        \"instruction_col\": \"Instruction\",\n",
    "        \"output_col\": \"Output\",\n",
    "        \"tag\": \"linux_commands\"\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mecha-org/linux-command-dataset\",\n",
    "        \"split\": \"train\",\n",
    "        \"instruction_col\": \"input\",\n",
    "        \"output_col\": \"output\",\n",
    "        \"tag\": \"linux_cmd_mecha\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b39b4-9443-42d0-b6e4-e2f14422b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load, normalize and tag\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "#loop through each dataset config\n",
    "for ds in DATASETS:\n",
    "    dataset = load_dataset(ds[\"name\"], split=ds[\"split\"])\n",
    "    #read instruction/output\n",
    "    text_col = ds[\"instruction_col\"]\n",
    "    answer_col = ds[\"output_col\"]\n",
    "\n",
    "    #convert each row of the dataset into a langchain document\n",
    "    def add_metadata(record):\n",
    "        #extract all fields except instruction + answer\n",
    "        metadata = {k: v for k, v in record.items() if k not in [text_col, answer_col]}\n",
    "        # add custom metadata field to identify source dataset\n",
    "        metadata[\"doc_type\"] = ds[\"tag\"]\n",
    "\n",
    "        #create unified text format -merges instruction and answer together (this will be mbedded for RAG)\n",
    "        content = f\"Instruction: {record[text_col]}\\nAnswer: {record[answer_col]}\"\n",
    "        return Document(page_content=content, metadata=metadata)\n",
    "       \n",
    "    #convert every record into a document\n",
    "    docs = [add_metadata(r) for r in dataset if r.get(text_col)]\n",
    "    #add processed documents for this dataset into the global list\n",
    "    all_documents.extend(docs)\n",
    "        \n",
    "        \n",
    "print(f\"Loaded {len(all_documents)} combined documents\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f285d7a-204b-4c28-8f53-20eda4efe5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug and verify column names\n",
    "ds1 = load_dataset(\"harpomaxx/unix-commands\", split=\"train\")\n",
    "ds2 = load_dataset(\"shikhardadhich/linux_commands\", split=\"train\")\n",
    "ds3 = load_dataset(\"mecha-org/linux-command-dataset\", split=\"train\")\n",
    "\n",
    "print(ds1.column_names)\n",
    "print(ds2.column_names)\n",
    "print(ds3.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d99bb-3a76-46d0-92d7-e08eb0e8522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_deduplicate(docs):\n",
    "    seen = set()\n",
    "    clean_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        #strip whitespace\n",
    "        lines = [line.strip() for line in doc.page_content.splitlines()]\n",
    "        content = \"\\n\".join(lines)\n",
    "        #collapse multiple spaces into one space \n",
    "        content = \" \".join(content.split())\n",
    "\n",
    "        #deduplicate\n",
    "        if content not in seen:\n",
    "            seen.add(content)\n",
    "            #create a new document with the same metadata\n",
    "            clean_docs.append(Document(page_content=content, metadata=doc.metadata))\n",
    "    \n",
    "    return clean_docs        \n",
    "\n",
    "#apply normalization and deduplication\n",
    "all_documents_clean = normalize_and_deduplicate(all_documents)\n",
    "print(f\"Documents after normalization and deduplication: {len(all_documents_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7db26-d147-4385-9f72-11a9eb51f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(all_documents_clean)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25049b6-c67c-4e0a-8bd2-787c3027ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check chunk character size in 3 first chunks\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"Chunk {i+1} length: {len(chunk.page_content)} chars\")\n",
    "    print(chunk.page_content)\n",
    "    print(chunk.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a20c6-ca2e-4bca-8558-58c0ac9a41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41592aeb-81ca-44a4-9a8a-92db156747bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "\n",
    "print(f\"Vectorstore created with {count:,} documents\")\n",
    "print(f\"Each embedding has {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89998600-accd-4a40-84c2-e47a0631d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a precise, highly knowledgeable Linux command assistant.\n",
    "Always answer with:\n",
    "- The most complete and standard Linux command, not minimal versions.\n",
    "- a brief explanation.\n",
    "- an example when useful.\n",
    "- use the recursive version if applicable.\n",
    "- never shorten commands.\n",
    "\n",
    "\n",
    "Use the retrieved context below if relevant.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d24257-6985-47b5-932b-34fc1dd2d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm = Ollama(temperature=0.7, model=MODEL),\n",
    "    retriever = retriever,\n",
    "    memory = memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a45e52-6c2c-4a0f-9045-bb68a8046334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b49cc-8758-4354-b41b-2eaffe4ad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2243e79-c8b5-40d4-aa64-b37ec3366a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Question: How do I list all files in a directory including hidden ones?\n",
      "Model Response: To list all files in a directory, including those that are hidden, you can use the following command:\n",
      "\n",
      "`ls -a`\n",
      "\n",
      "Explanation: The `-a` option tells `ls` to display all files and directories, including hidden ones.\n",
      "\n",
      "Example: If you want to see a list of all files in your current directory, type:\n",
      "\n",
      "`ls -a`\n",
      "\n",
      "This will show you both visible and hidden files and directories.\n",
      "Score: 2 / 3\n",
      "Status:  PASS\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: How do I find a file containing a specific text string?\n",
      "Model Response: To find a file containing a specific text string, use the `grep` command with the specified text string as an argument.\n",
      "\n",
      "- Command: `grep search_string file1 file2 file3`\n",
      "- Explanation: The `grep` command searches for lines that contain the specified text string in one or more files.\n",
      "- Example: To find all lines containing \"example\" in both \"file1.txt\" and \"file2.txt\", use:\n",
      "```bash\n",
      "grep 'example' file1.txt file2.txt\n",
      "```\n",
      "\n",
      "When searching multiple files, you can also use the `-r` option to search recursively:\n",
      "\n",
      "- Command: `grep -r search_string directory`\n",
      "- Explanation: The `-r` option tells `grep` to search for the specified text string in all subdirectories of the specified directory.\n",
      "- Example: To find all lines containing \"example\" in the current directory and its subdirectories, use:\n",
      "```bash\n",
      "grep -r 'example' .\n",
      "```\n",
      "\n",
      "Note: If you want to exclude a specific file or directory from the search, you can add it to the command using the `-v` option.\n",
      "\n",
      "Example:\n",
      "```bash\n",
      "grep -v 'exclude_file.txt' -r 'example' .\n",
      "```\n",
      "Score: 3 / 4\n",
      "Status:  PASS\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Explain the difference between grep and sed.\n",
      "Model Response: The main difference between the `grep` and `sed` commands in Linux is their purpose:\n",
      "\n",
      "*   `grep` (Global Regular Expression Print) is a command used to search for lines containing a specified pattern. It searches for the pattern in one or more files, displaying only those that contain the match.\n",
      "*   `sed` (Stream Editor) is a command used to edit and manipulate text within files. While it can also be used for searching patterns, its primary function is to perform complex text editing operations, such as substituting, inserting, or deleting text.\n",
      "\n",
      "Example:\n",
      "\n",
      "Suppose we have a file named \"users.txt\" containing user information in the following format:\n",
      "```\n",
      "John Doe 123 Main St\n",
      "Jane Smith 456 Elm St\n",
      "Bob Johnson 789 Oak St\n",
      "```\n",
      "To find all lines containing the word \"Doe\", you would use `grep`:\n",
      "\n",
      "```bash\n",
      "cat users.txt | grep \"Doe\"\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "John Doe 123 Main St\n",
      "```\n",
      "\n",
      "If you want to replace the word \"Doe\" with \"Johnson\" in the same file, you can use `sed`:\n",
      "\n",
      "```bash\n",
      "sed -i 's/Doe/Johnson/g' users.txt\n",
      "```\n",
      "\n",
      "This command will update all occurrences of \"Doe\" with \"Johnson\", replacing them.\n",
      "\n",
      "In summary, while both commands can be used for searching patterns, `grep` is primarily a search command, whereas `sed` is a stream editor that allows more complex text editing operations.\n",
      "Score: 5 / 5\n",
      "Status:  PASS\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: How do I search for a file by name?\n",
      "Model Response: To search for a specific text string within files, you can use the `grep` command.\n",
      "\n",
      "- The most complete and standard Linux command is: `grep [search_string] *file`\n",
      "- Brief explanation: `grep` stands for \"Global Regular Expression Print\". It searches for lines in one or more files that contain a match to the specified regular expression.\n",
      "- Example when useful:\n",
      "```bash\n",
      "# Search for 'example' in all .txt and .log files\n",
      "grep -r 'example' *.txt *.log\n",
      "```\n",
      "- Recursive version: `grep [search_string] *file` (by default, `grep` is recursive)\n",
      "\n",
      "Alternatively, you can use `ag` command which is faster and more efficient than traditional `grep`.\n",
      "\n",
      "- The most complete and standard Linux command with ag is: `ag [search_string] *file`\n",
      "- Brief explanation: Similar to `grep`, but more powerful and efficient.\n",
      "- Example when useful:\n",
      "```bash\n",
      "# Search for 'example' in all .txt and .log files using ag\n",
      "ag -r 'example' *.txt *.log\n",
      "```\n",
      "Note that `ag` requires installation using package manager (e.g., `apt-get install ag` on Debian/Ubuntu or `yum install ag` on RHEL/CentOS).\n",
      "Score: 0 / 2\n",
      "Status:  FAIL\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: And how about searching inside files?\n",
      "Model Response: To search for a file by name using find, you can use:\n",
      "\n",
      "```bash\n",
      "find . -name myfile.txt\n",
      "```\n",
      "\n",
      "Explanation: The dot (.) represents the current working directory. If you want to search in a different directory, replace the dot with the desired path.\n",
      "\n",
      "Example: To search for `myfile.txt` in your home directory, use:\n",
      "```bash\n",
      "find ~/ -name myfile.txt\n",
      "```\n",
      "\n",
      "Note that locate may not always find what you're looking for, as its database is periodically updated and might not reflect changes made since the last update. If you want to use locate, make sure to update it first using `sudo updatedb`.\n",
      "Score: 1 / 3\n",
      "Status:  FAIL\n"
     ]
    }
   ],
   "source": [
    "#Testing RAG repsonses\n",
    "\n",
    "# --- 1. Define test cases --------------------------------------------------\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"How do I list all files in a directory including hidden ones?\",\n",
    "        \"expected_keywords\": [\"ls -a\", \"ls -la\", \"hidden\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I find a file containing a specific text string?\",\n",
    "        \"expected_keywords\": [\"grep\", \"grep -r\", \"string\", \"filename\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain the difference between grep and sed.\",\n",
    "        \"expected_keywords\": [\"grep\", \"sed\", \"search\", \"edit\", \"replace\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I search for a file by name?\",\n",
    "        \"expected_keywords\": [\"find\", \"-name\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"And how about searching inside files?\",\n",
    "        \"expected_keywords\": [\"grep\", \"string\", \"file\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- 2. Loosened evaluation function ---------------------------------------\n",
    "\n",
    "def score_answer(answer, expected_keywords, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Loosened evaluation:\n",
    "    - Partial score for each keyword found\n",
    "    - Pass if ratio >= threshold\n",
    "    \"\"\"\n",
    "    answer_lower = answer.lower()\n",
    "    score = 0\n",
    "    for kw in expected_keywords:\n",
    "        # simple substring OR regex for variations\n",
    "        pattern = re.escape(kw.lower())\n",
    "        if re.search(pattern, answer_lower):\n",
    "            score += 1\n",
    "\n",
    "    total = len(expected_keywords)\n",
    "    ratio = score / total\n",
    "    passed = ratio >= threshold  # pass if >= threshold (60% by default)\n",
    "    return score, total, passed\n",
    "\n",
    "# --- 3. Run evaluation ------------------------------------------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "for test in test_cases:\n",
    "    q = test[\"question\"]\n",
    "    expected = test[\"expected_keywords\"]\n",
    "\n",
    "    response = chat(q, history=[])  # no conversation memory\n",
    "    score, total, passed = score_answer(response, expected)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"response\": response,\n",
    "        \"score\": score,\n",
    "        \"total\": total,\n",
    "        \"passed\": passed\n",
    "    })\n",
    "\n",
    "# --- 4. Print report --------------------------------------------------------\n",
    "\n",
    "for result in results:\n",
    "    print(\"\\n--------------------------------------------------\")\n",
    "    print(\"Question:\", result[\"question\"])\n",
    "    print(\"Model Response:\", result[\"response\"])\n",
    "    print(f\"Score: {result['score']} / {result['total']}\")\n",
    "    print(\"Status:\", \" PASS\" if result[\"passed\"] else \" FAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96a36a-3280-42be-b802-0c994646aa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
